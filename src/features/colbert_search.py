#!/usr/bin/env python3
"""
ColBERT Search Engine for Vault Intelligence System V2

BGE-M3 ColBERT ì„ë² ë”© ê¸°ë°˜ í† í° ìˆ˜ì¤€ late interaction ê²€ìƒ‰
"""

import os
import logging
from typing import List, Dict, Optional, Tuple, Union
from dataclasses import dataclass
import numpy as np
import torch

try:
    from FlagEmbedding import BGEM3FlagModel
    BGE_AVAILABLE = True
except ImportError:
    BGE_AVAILABLE = False
    logging.warning("FlagEmbedding not available. ColBERT functionality will be disabled.")

from .advanced_search import SearchResult, Document

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ColBERTResult:
    """ColBERT ê²€ìƒ‰ ê²°ê³¼"""
    document: Document
    colbert_score: float
    token_similarities: List[Tuple[str, str, float]]  # (query_token, doc_token, similarity)
    max_sim_per_query_token: List[float]  # ê° ì¿¼ë¦¬ í† í°ì˜ ìµœëŒ€ ìœ ì‚¬ë„
    rank: int = 0


class ColBERTSearchEngine:
    """BGE-M3 ColBERT ê¸°ë°˜ í† í° ìˆ˜ì¤€ late interaction ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-m3",
        device: Optional[str] = None,
        use_fp16: bool = True,
        cache_folder: Optional[str] = None,
        max_length: int = 4096,
        cache_dir: Optional[str] = None,
        enable_cache: bool = True
    ):
        """
        Args:
            model_name: BGE-M3 ëª¨ë¸ëª…
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
            use_fp16: FP16 ì •ë°€ë„ ì‚¬ìš©
            cache_folder: ëª¨ë¸ ìºì‹œ í´ë”
            max_length: ìµœëŒ€ í† í° ê¸¸ì´
            cache_dir: ì„ë² ë”© ìºì‹œ ë””ë ‰í† ë¦¬
            enable_cache: ìºì‹± í™œì„±í™” ì—¬ë¶€
        """
        self.model_name = model_name
        self.device = device
        self.use_fp16 = use_fp16
        self.cache_folder = cache_folder
        self.max_length = max_length
        self.model = None
        self.is_initialized = False
        self.enable_cache = enable_cache
        
        # ColBERT ì„ë² ë”© ì €ì¥ì†Œ
        self.documents: List[Document] = []
        self.colbert_embeddings: List[np.ndarray] = []  # ë¬¸ì„œë³„ ColBERT ì„ë² ë”©
        self.document_tokens: List[List[str]] = []  # ë¬¸ì„œë³„ í† í°
        self.is_indexed = False
        
        # ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.cache = None
        if cache_dir and enable_cache:
            try:
                from ..core.embedding_cache import EmbeddingCache
                self.cache = EmbeddingCache(cache_dir)
                logger.info("ColBERT ìºì‹œ ì‹œìŠ¤í…œ í™œì„±í™”")
            except Exception as e:
                logger.warning(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.cache = None
        
        # ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if not BGE_AVAILABLE:
            logger.warning("FlagEmbedding ë¯¸ì„¤ì¹˜ë¡œ ì¸í•´ ColBERT ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return
        
        logger.info(f"ColBERT ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”: {model_name}")
        self._initialize_model()
    
    def _initialize_model(self):
        """BGE-M3 ëª¨ë¸ ì´ˆê¸°í™”"""
        if not BGE_AVAILABLE:
            return
        
        try:
            # ìºì‹œ í´ë” ì„¤ì •
            if self.cache_folder:
                os.environ['HF_HOME'] = self.cache_folder
                os.environ['TRANSFORMERS_CACHE'] = self.cache_folder
            
            # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
            if self.device is None:
                if torch.cuda.is_available():
                    self.device = "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    self.device = "mps"
                else:
                    self.device = "cpu"
            
            logger.info(f"ColBERT ë””ë°”ì´ìŠ¤: {self.device}")
            
            # BGE-M3 ëª¨ë¸ ë¡œë“œ
            self.model = BGEM3FlagModel(
                self.model_name,
                use_fp16=self.use_fp16,
                device=self.device
            )
            
            self.is_initialized = True
            logger.info("ColBERT BGE-M3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ColBERT ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
    
    def is_available(self) -> bool:
        """ColBERT ì—”ì§„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return BGE_AVAILABLE and self.is_initialized
    
    def build_index(self, documents: List[Document], batch_size: int = 4, max_documents: Optional[int] = None, force_rebuild: bool = False) -> bool:
        """
        ColBERT ì¸ë±ìŠ¤ êµ¬ì¶• (ìºì‹œ ì§€ì›)
        
        Args:
            documents: ì¸ë±ì‹±í•  ë¬¸ì„œ ëª©ë¡
            batch_size: ë°°ì¹˜ í¬ê¸°
            max_documents: ìµœëŒ€ ë¬¸ì„œ ìˆ˜ ì œí•œ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
            force_rebuild: ê°•ì œ ì¬êµ¬ì¶• ì—¬ë¶€
            
        Returns:
            ì¸ë±ì‹± ì„±ê³µ ì—¬ë¶€
        """
        if not self.is_available():
            logger.warning("ColBERT ì—”ì§„ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return False
        
        if not documents:
            logger.warning("ì¸ë±ì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        logger.info(f"ColBERT ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ")
        
        # max_documentsê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì œí•œ
        if max_documents and len(documents) > max_documents:
            logger.warning(f"âš ï¸  ë¬¸ì„œ ìˆ˜ ì œí•œ: {max_documents}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            documents = documents[:max_documents]
        
        try:
            self.documents = documents
            self.colbert_embeddings = []
            self.document_tokens = []
            
            cached_count = 0
            new_count = 0
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for i in range(0, len(documents), batch_size):
                batch_docs = documents[i:i + batch_size]
                batch_to_process = []
                batch_indices = []
                
                # ìºì‹œ í™•ì¸
                for idx, doc in enumerate(batch_docs):
                    if self.cache and not force_rebuild and hasattr(doc, 'path') and doc.path:
                        # íŒŒì¼ í•´ì‹œ ê³„ì‚°
                        file_hash = self.cache._calculate_file_hash(doc.path)
                        cached = self.cache.get_colbert_embedding(doc.path, file_hash)
                        
                        if cached:
                            # ìºì‹œëœ ì„ë² ë”© ì‚¬ìš©
                            self.colbert_embeddings.append(cached['colbert_embedding'])
                            tokens = self._approximate_tokens(doc.content) if cached.get('token_embeddings') is None else cached.get('token_embeddings', ["[CACHED]"])
                            self.document_tokens.append(tokens)
                            cached_count += 1
                            logger.debug(f"ìºì‹œ ì‚¬ìš©: {doc.path}")
                        else:
                            # ìƒˆë¡œ ì²˜ë¦¬ í•„ìš”
                            batch_to_process.append(doc)
                            batch_indices.append(i + idx)
                    else:
                        # ìºì‹œ ë¹„í™œì„±í™” ë˜ëŠ” ê°•ì œ ì¬êµ¬ì¶•
                        batch_to_process.append(doc)
                        batch_indices.append(i + idx)
                
                # ìƒˆë¡œìš´ ë¬¸ì„œë“¤ë§Œ ì²˜ë¦¬
                if batch_to_process:
                    batch_texts = [doc.content for doc in batch_to_process]
                    
                    logger.info(f"ColBERT ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì¤‘... (ìºì‹œ: {cached_count}, ì‹ ê·œ: {new_count})")
                    
                    try:
                        # BGE-M3ë¡œ ColBERT ì„ë² ë”© ìƒì„±
                        result = self.model.encode(
                            batch_texts,
                            batch_size=len(batch_texts),
                            max_length=self.max_length,
                            return_dense=False,
                            return_sparse=False,
                            return_colbert_vecs=True  # ColBERT ì„ë² ë”© í™œì„±í™”
                        )
                        
                        # ColBERT ë²¡í„°ì™€ í† í° ì •ë³´ ì €ì¥
                        colbert_vecs = result['colbert_vecs']
                        
                        for j, (colbert_vec, doc) in enumerate(zip(colbert_vecs, batch_to_process)):
                            self.colbert_embeddings.append(colbert_vec)
                            
                            # í† í° ì •ë³´ ìƒì„±
                            tokens = self._approximate_tokens(doc.content)
                            self.document_tokens.append(tokens)
                            new_count += 1
                            
                            # ìºì‹œì— ì €ì¥
                            if self.cache and hasattr(doc, 'path') and doc.path:
                                self.cache.store_colbert_embedding(
                                    file_path=doc.path,
                                    colbert_embedding=colbert_vec,
                                    token_embeddings=None,  # í† í° ì„ë² ë”©ì€ ë³„ë„ ì €ì¥í•˜ì§€ ì•ŠìŒ
                                    model_name=self.model_name,
                                    num_tokens=len(tokens)
                                )
                                logger.debug(f"ìºì‹œ ì €ì¥: {doc.path}")
                        
                        logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: {len(batch_to_process)}ê°œ ë¬¸ì„œ ì²˜ë¦¬")
                        
                    except Exception as e:
                        logger.error(f"ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        # í´ë°±: ë¹ˆ ì„ë² ë”©
                        for doc in batch_to_process:
                            self.colbert_embeddings.append(np.zeros((10, 1024)))  # ì„ì‹œ í¬ê¸°
                            self.document_tokens.append(["[EMPTY]"])
                            new_count += 1
            
            self.is_indexed = True
            logger.info(f"âœ… ColBERT ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: ì´ {len(self.colbert_embeddings)}ê°œ (ìºì‹œ: {cached_count}, ì‹ ê·œ: {new_count})")
            return True
            
        except Exception as e:
            logger.error(f"ColBERT ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            return False
    
    def _approximate_tokens(self, text: str, max_tokens: int = 512) -> List[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ëŒ€ëµì ì¸ í† í°ìœ¼ë¡œ ë¶„í• 
        (ì‹¤ì œë¡œëŠ” BGE-M3 tokenizerë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ì§€ë§Œ ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜ ì‚¬ìš©)
        """
        # ê°„ë‹¨í•œ í† í°í™” (ê³µë°± ë° êµ¬ë‘ì  ê¸°ì¤€)
        import re
        tokens = re.findall(r'\b\w+\b', text.lower())
        return tokens[:max_tokens]  # ìµœëŒ€ í† í° ìˆ˜ ì œí•œ
    
    def search(
        self,
        query: str,
        top_k: int = 10,
        similarity_threshold: float = 0.0
    ) -> List[ColBERTResult]:
        """
        ColBERT ê¸°ë°˜ late interaction ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            ColBERT ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
        """
        if not self.is_available() or not self.is_indexed:
            logger.warning("ColBERT ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        if not query.strip():
            logger.warning("ë¹ˆ ì¿¼ë¦¬ì…ë‹ˆë‹¤.")
            return []
        
        logger.info(f"ColBERT ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        try:
            # ì¿¼ë¦¬ ColBERT ì„ë² ë”© ìƒì„±
            query_result = self.model.encode(
                [query],
                batch_size=1,
                max_length=self.max_length,
                return_dense=False,
                return_sparse=False,
                return_colbert_vecs=True
            )
            
            query_colbert = query_result['colbert_vecs'][0]  # (query_tokens, dim)
            query_tokens = self._approximate_tokens(query)
            
            logger.info(f"ì¿¼ë¦¬ ColBERT ì„ë² ë”©: {query_colbert.shape}, í† í° ìˆ˜: {len(query_tokens)}")
            
            # ê° ë¬¸ì„œì™€ì˜ late interaction ê³„ì‚°
            results = []
            
            for i, (doc, doc_colbert, doc_tokens) in enumerate(zip(
                self.documents, self.colbert_embeddings, self.document_tokens
            )):
                try:
                    # Late interaction: max_sim ê³„ì‚°
                    score, token_similarities, max_sims = self._compute_late_interaction(
                        query_colbert, doc_colbert, query_tokens, doc_tokens
                    )
                    
                    if score >= similarity_threshold:
                        result = ColBERTResult(
                            document=doc,
                            colbert_score=score,
                            token_similarities=token_similarities,
                            max_sim_per_query_token=max_sims,
                            rank=0  # ì„ì‹œ, ì •ë ¬ í›„ ì—…ë°ì´íŠ¸
                        )
                        results.append(result)
                
                except Exception as e:
                    logger.warning(f"ë¬¸ì„œ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x.colbert_score, reverse=True)
            
            # ìƒìœ„ Kê°œ ì„ íƒ ë° ìˆœìœ„ ì—…ë°ì´íŠ¸
            top_results = results[:top_k]
            for rank, result in enumerate(top_results):
                result.rank = rank + 1
            
            logger.info(f"ColBERT ê²€ìƒ‰ ì™„ë£Œ: {len(top_results)}ê°œ ê²°ê³¼")
            return top_results
            
        except Exception as e:
            logger.error(f"ColBERT ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _compute_late_interaction(
        self,
        query_embeddings: np.ndarray,  # (query_tokens, dim)
        doc_embeddings: np.ndarray,    # (doc_tokens, dim)
        query_tokens: List[str],
        doc_tokens: List[str]
    ) -> Tuple[float, List[Tuple[str, str, float]], List[float]]:
        """
        ColBERT late interaction ê³„ì‚°
        
        Returns:
            (ì „ì²´_ì ìˆ˜, í† í°_ìœ ì‚¬ë„_ìŒ, ì¿¼ë¦¬í† í°ë³„_ìµœëŒ€ìœ ì‚¬ë„)
        """
        try:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° (query_tokens x doc_tokens)
            similarities = np.dot(query_embeddings, doc_embeddings.T)
            
            # ê° ì¿¼ë¦¬ í† í°ì— ëŒ€í•´ ë¬¸ì„œ í† í° ì¤‘ ìµœëŒ€ ìœ ì‚¬ë„ ê³„ì‚°
            max_similarities = np.max(similarities, axis=1)  # (query_tokens,)
            
            # ì „ì²´ ì ìˆ˜: ì¿¼ë¦¬ í† í°ë³„ ìµœëŒ€ ìœ ì‚¬ë„ì˜ í‰ê· 
            total_score = float(np.mean(max_similarities))
            
            # ìƒìœ„ í† í° ìœ ì‚¬ë„ ìŒ ì¶”ì¶œ (ë””ë²„ê¹…ìš©)
            token_similarities = []
            for i, query_token in enumerate(query_tokens[:len(max_similarities)]):
                # í•´ë‹¹ ì¿¼ë¦¬ í† í°ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ í† í° ì°¾ê¸°
                best_doc_idx = np.argmax(similarities[i])
                if best_doc_idx < len(doc_tokens):
                    best_doc_token = doc_tokens[best_doc_idx]
                    best_similarity = similarities[i, best_doc_idx]
                    
                    token_similarities.append((
                        query_token, 
                        best_doc_token, 
                        float(best_similarity)
                    ))
            
            return total_score, token_similarities, max_similarities.tolist()
            
        except Exception as e:
            logger.error(f"Late interaction ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0, [], []
    
    def convert_to_search_results(self, colbert_results: List[ColBERTResult]) -> List[SearchResult]:
        """ColBERT ê²°ê³¼ë¥¼ SearchResult í˜•íƒœë¡œ ë³€í™˜"""
        search_results = []
        
        for colbert_result in colbert_results:
            # í† í° ë§¤ì¹­ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            matched_keywords = [
                f"{query_token}â†’{doc_token}({sim:.3f})"
                for query_token, doc_token, sim in colbert_result.token_similarities[:3]
            ]
            
            # ìŠ¤ë‹ˆí« ìƒì„± (ìµœê³  ìœ ì‚¬ë„ í† í° ì£¼ë³€ í…ìŠ¤íŠ¸)
            snippet = self._generate_colbert_snippet(
                colbert_result.document.content,
                colbert_result.token_similarities
            )
            
            search_result = SearchResult(
                document=colbert_result.document,
                similarity_score=colbert_result.colbert_score,
                match_type="colbert",
                matched_keywords=matched_keywords,
                snippet=snippet,
                rank=colbert_result.rank
            )
            search_results.append(search_result)
        
        return search_results
    
    def _generate_colbert_snippet(
        self, 
        content: str, 
        token_similarities: List[Tuple[str, str, float]],
        context_window: int = 100
    ) -> str:
        """ColBERT í† í° ë§¤ì¹­ ê¸°ë°˜ ìŠ¤ë‹ˆí« ìƒì„±"""
        if not token_similarities or not content:
            return content[:200] + "..." if len(content) > 200 else content
        
        # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ í† í° ì°¾ê¸°
        best_match = max(token_similarities, key=lambda x: x[2])
        best_doc_token = best_match[1]
        
        # í•´ë‹¹ í† í° ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        content_lower = content.lower()
        token_pos = content_lower.find(best_doc_token.lower())
        
        if token_pos != -1:
            start = max(0, token_pos - context_window)
            end = min(len(content), token_pos + len(best_doc_token) + context_window)
            snippet = content[start:end]
            
            # ì•ë’¤ ìƒëµ í‘œì‹œ
            if start > 0:
                snippet = "..." + snippet
            if end < len(content):
                snippet = snippet + "..."
                
            return snippet
        
        # í´ë°±: ë¬¸ì„œ ì‹œì‘ ë¶€ë¶„
        return content[:200] + "..." if len(content) > 200 else content


def test_colbert_search():
    """ColBERT ê²€ìƒ‰ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ColBERT ê²€ìƒ‰ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    
    # ì˜ì¡´ì„± ì²´í¬
    if not BGE_AVAILABLE:
        print("âŒ FlagEmbeddingì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False
    
    try:
        # ColBERT ì—”ì§„ ì´ˆê¸°í™”
        engine = ColBERTSearchEngine(device="cpu")  # í…ŒìŠ¤íŠ¸ìš© CPU ì‚¬ìš©
        
        if not engine.is_available():
            print("âŒ ColBERT ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        print("âœ… ColBERT ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ")
        print(f"   ëª¨ë¸: {engine.model_name}")
        print(f"   ë””ë°”ì´ìŠ¤: {engine.device}")
        
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    test_colbert_search()