#!/usr/bin/env python3
"""
Query Expansion Engine for Vault Intelligence System V2

ì¿¼ë¦¬ í™•ì¥ ê¸°ëŠ¥:
- ë™ì˜ì–´ í™•ì¥ (Synonym Expansion)
- HyDE (Hypothetical Document Embeddings)
- ê´€ë ¨ì–´ ì¶”ì²œ (Related Terms)
"""

import os
import logging
from typing import List, Dict, Optional, Tuple, Union, Set
from dataclasses import dataclass
import json
import re

# BGE-M3 ëª¨ë¸
try:
    from FlagEmbedding import BGEM3FlagModel
    BGE_AVAILABLE = True
except ImportError:
    BGE_AVAILABLE = False
    logging.warning("FlagEmbedding not available. Query expansion will be limited.")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ExpandedQuery:
    """í™•ì¥ëœ ì¿¼ë¦¬"""
    original_query: str
    expanded_terms: List[str]
    synonyms: List[str]
    related_terms: List[str]
    hypothetical_doc: Optional[str] = None
    expansion_method: str = "basic"


class KoreanSynonymExpander:
    """í•œêµ­ì–´ ë™ì˜ì–´ í™•ì¥ê¸°"""
    
    def __init__(self):
        """í•œêµ­ì–´ ë™ì˜ì–´ ì‚¬ì „ ì´ˆê¸°í™”"""
        self.synonym_dict = {
            # ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê´€ë ¨
            "TDD": ["í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ", "í…ŒìŠ¤íŠ¸ ë“œë¦¬ë¸ ê°œë°œ", "Test Driven Development", "test driven development"],
            "í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ": ["TDD", "í…ŒìŠ¤íŠ¸ ë“œë¦¬ë¸ ê°œë°œ", "Test Driven Development"],
            "í…ŒìŠ¤íŠ¸ ë“œë¦¬ë¸ ê°œë°œ": ["TDD", "í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ", "Test Driven Development"],
            
            "ë¦¬íŒ©í† ë§": ["refactoring", "ì½”ë“œ ê°œì„ ", "êµ¬ì¡° ê°œì„ ", "ì½”ë“œ ì •ë¦¬"],
            "refactoring": ["ë¦¬íŒ©í† ë§", "ì½”ë“œ ê°œì„ ", "êµ¬ì¡° ê°œì„ "],
            
            "í´ë¦°ì½”ë“œ": ["clean code", "ê¹¨ë—í•œ ì½”ë“œ", "ì¢‹ì€ ì½”ë“œ", "ê°€ë…ì„±"],
            "clean code": ["í´ë¦°ì½”ë“œ", "ê¹¨ë—í•œ ì½”ë“œ", "ì¢‹ì€ ì½”ë“œ"],
            
            "ë””ìì¸íŒ¨í„´": ["design pattern", "ì„¤ê³„ íŒ¨í„´", "íŒ¨í„´"],
            "design pattern": ["ë””ìì¸íŒ¨í„´", "ì„¤ê³„ íŒ¨í„´", "íŒ¨í„´"],
            
            "ì•„í‚¤í…ì²˜": ["architecture", "êµ¬ì¡°", "ì„¤ê³„", "ì•„í‚¤í…ì³"],
            "architecture": ["ì•„í‚¤í…ì²˜", "êµ¬ì¡°", "ì„¤ê³„"],
            
            "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤": ["microservice", "MSA", "ë§ˆì´í¬ë¡œ ì„œë¹„ìŠ¤"],
            "microservice": ["ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤", "MSA", "ë§ˆì´í¬ë¡œ ì„œë¹„ìŠ¤"],
            
            # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
            "ìë°”": ["java", "Java"],
            "java": ["ìë°”", "Java"],
            "íŒŒì´ì¬": ["python", "Python"],
            "python": ["íŒŒì´ì¬", "Python"],
            "ìë°”ìŠ¤í¬ë¦½íŠ¸": ["javascript", "JS", "js"],
            "javascript": ["ìë°”ìŠ¤í¬ë¦½íŠ¸", "JS", "js"],
            
            # í”„ë ˆì„ì›Œí¬
            "ìŠ¤í”„ë§": ["spring", "Spring", "ìŠ¤í”„ë§ë¶€íŠ¸", "spring boot"],
            "spring": ["ìŠ¤í”„ë§", "Spring", "ìŠ¤í”„ë§ë¶€íŠ¸"],
            "ë¦¬ì•¡íŠ¸": ["react", "React"],
            "react": ["ë¦¬ì•¡íŠ¸", "React"],
            
            # ê°œë°œ ë°©ë²•ë¡ 
            "ì• ìì¼": ["agile", "Agile", "ìŠ¤í¬ëŸ¼", "scrum"],
            "agile": ["ì• ìì¼", "Agile", "ìŠ¤í¬ëŸ¼"],
            "ìŠ¤í¬ëŸ¼": ["scrum", "Scrum", "ì• ìì¼"],
            "scrum": ["ìŠ¤í¬ëŸ¼", "Scrum", "ì• ìì¼"],
            
            # ì¼ë°˜ì ì¸ ìš©ì–´
            "êµ¬í˜„": ["implementation", "ê°œë°œ", "ì½”ë”©", "ì‘ì„±"],
            "implementation": ["êµ¬í˜„", "ê°œë°œ", "ì½”ë”©"],
            "ê°œë°œ": ["development", "êµ¬í˜„", "ì œì‘"],
            "development": ["ê°œë°œ", "êµ¬í˜„", "ì œì‘"],
            
            "í•™ìŠµ": ["learning", "ê³µë¶€", "ìŠ¤í„°ë””", "ì—°êµ¬"],
            "learning": ["í•™ìŠµ", "ê³µë¶€", "ìŠ¤í„°ë””"],
            "ê³µë¶€": ["study", "í•™ìŠµ", "ì—°êµ¬"],
            "study": ["ê³µë¶€", "í•™ìŠµ", "ì—°êµ¬"],
        }
        
        logger.info(f"í•œêµ­ì–´ ë™ì˜ì–´ ì‚¬ì „ ë¡œë”© ì™„ë£Œ: {len(self.synonym_dict)}ê°œ ì—”íŠ¸ë¦¬")
    
    def expand_synonyms(self, query: str) -> List[str]:
        """ë™ì˜ì–´ í™•ì¥"""
        synonyms = set()
        
        # ì¿¼ë¦¬ë¥¼ ë‹¨ì–´ë¡œ ë¶„í• 
        words = self._tokenize_query(query)
        
        for word in words:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
            word_lower = word.lower()
            word_original = word
            
            # ì§ì ‘ ë§¤ì¹­
            if word_lower in self.synonym_dict:
                synonyms.update(self.synonym_dict[word_lower])
            elif word_original in self.synonym_dict:
                synonyms.update(self.synonym_dict[word_original])
            
            # ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
            for key, values in self.synonym_dict.items():
                if word_lower in key.lower() or key.lower() in word_lower:
                    synonyms.update(values)
        
        # ì›ë³¸ ì¿¼ë¦¬ì˜ ë‹¨ì–´ë“¤ ì œì™¸
        synonyms.discard(query)
        synonyms.discard(query.lower())
        for word in words:
            synonyms.discard(word)
            synonyms.discard(word.lower())
        
        return list(synonyms)
    
    def _tokenize_query(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ë¥¼ í† í°ìœ¼ë¡œ ë¶„í• """
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë¥¼ í¬í•¨í•œ ë‹¨ì–´ ì¶”ì¶œ
        tokens = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query)
        return tokens


class HyDEGenerator:
    """Hypothetical Document Embeddings (HyDE) ìƒì„±ê¸°"""
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-m3",
        device: Optional[str] = None,
        use_fp16: bool = True
    ):
        """
        Args:
            model_name: BGE ëª¨ë¸ëª…
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
            use_fp16: FP16 ì‚¬ìš© ì—¬ë¶€
        """
        self.model_name = model_name
        self.device = device
        self.use_fp16 = use_fp16
        self.model = None
        self.is_initialized = False
        
        if BGE_AVAILABLE:
            self._initialize_model()
    
    def _initialize_model(self):
        """BGE-M3 ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
            if self.device is None:
                import torch
                if torch.cuda.is_available():
                    self.device = "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    self.device = "mps"
                else:
                    self.device = "cpu"
            
            self.model = BGEM3FlagModel(
                self.model_name,
                use_fp16=self.use_fp16,
                device=self.device
            )
            
            self.is_initialized = True
            logger.info(f"HyDE ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
            
        except Exception as e:
            logger.error(f"HyDE ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
    
    def generate_hypothetical_document(self, query: str) -> str:
        """
        ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒì˜ ë¬¸ì„œ ìƒì„±
        (ì‹¤ì œë¡œëŠ” ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ì—¬ ë” ìì„¸í•œ ë¬¸ì„œ í˜•íƒœë¡œ ë³€í™˜)
        """
        if not self.is_initialized:
            # í´ë°±: ê·œì¹™ ê¸°ë°˜ í™•ì¥
            return self._rule_based_expansion(query)
        
        # í˜„ì¬ëŠ” ê·œì¹™ ê¸°ë°˜ êµ¬í˜„ (í–¥í›„ LLM í†µí•© ê°€ëŠ¥)
        return self._rule_based_expansion(query)
    
    def _rule_based_expansion(self, query: str) -> str:
        """ê·œì¹™ ê¸°ë°˜ ë¬¸ì„œ í™•ì¥"""
        # ì¿¼ë¦¬ ë¶„ì„
        words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query.lower())
        
        # ë„ë©”ì¸ë³„ í™•ì¥ í…œí”Œë¦¿
        templates = {
            # ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ
            "tdd": "í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ(TDD)ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë°©ë²•ë¡  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. Red-Green-Refactor ì‚¬ì´í´ì„ í†µí•´ ë¨¼ì € ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•˜ëŠ” ìµœì†Œí•œì˜ ì½”ë“œë¥¼ êµ¬í˜„í•œ í›„, ì½”ë“œë¥¼ ê°œì„ í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì½”ë“œ í’ˆì§ˆì„ ë†’ì´ê³  ë²„ê·¸ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            
            "ë¦¬íŒ©í† ë§": "ë¦¬íŒ©í† ë§ì€ ê¸°ëŠ¥ì€ ë³€ê²½í•˜ì§€ ì•Šìœ¼ë©´ì„œ ì½”ë“œì˜ êµ¬ì¡°ì™€ ê°€ë…ì„±ì„ ê°œì„ í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì½”ë“œ ìŠ¤ë©œì„ ì œê±°í•˜ê³ , ì¤‘ë³µì„ ì¤„ì´ë©°, ë” ë‚˜ì€ ì„¤ê³„ íŒ¨í„´ì„ ì ìš©í•˜ì—¬ ìœ ì§€ë³´ìˆ˜ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì•ˆì „í•œ ë¦¬íŒ©í† ë§ì„ ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            
            "í´ë¦°ì½”ë“œ": "í´ë¦° ì½”ë“œëŠ” ì½ê¸° ì‰½ê³ , ì´í•´í•˜ê¸° ì‰¬ìš°ë©°, ë³€ê²½í•˜ê¸° ì‰¬ìš´ ì½”ë“œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ë¯¸ ìˆëŠ” ë³€ìˆ˜ëª…, ì‘ê³  ì§‘ì¤‘ëœ í•¨ìˆ˜, ëª…í™•í•œ ì£¼ì„, ì¼ê´€ëœ ì½”ë”© ìŠ¤íƒ€ì¼ì„ í†µí•´ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¢‹ì€ ì½”ë“œëŠ” ë‹¤ë¥¸ ê°œë°œìê°€ ì‰½ê²Œ ì´í•´í•˜ê³  ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            
            "ì•„í‚¤í…ì²˜": "ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜ëŠ” ì‹œìŠ¤í…œì˜ êµ¬ì¡°ì™€ ì„¤ê³„ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì»´í¬ë„ŒíŠ¸ ê°„ì˜ ê´€ê³„, ë°ì´í„° íë¦„, ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„ ë“±ì„ í¬í•¨í•˜ë©°, í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„±, ì„±ëŠ¥ì„ ê³ ë ¤í•˜ì—¬ ì„¤ê³„ë©ë‹ˆë‹¤. ì¢‹ì€ ì•„í‚¤í…ì²˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤.",
            
            "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤": "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ê³  ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ë“¤ë¡œ ë¶„í•´í•˜ëŠ” ì„¤ê³„ ë°©ì‹ì…ë‹ˆë‹¤. ê° ì„œë¹„ìŠ¤ëŠ” íŠ¹ì • ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ë©°, ë…ë¦½ì ìœ¼ë¡œ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ í†µì‹ í•˜ë©°, ì¥ì•  ê²©ë¦¬ì™€ ê¸°ìˆ  ë‹¤ì–‘ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.",
            
            # í•™ìŠµ ê´€ë ¨
            "í•™ìŠµ": "íš¨ê³¼ì ì¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¡ ê³¼ ì‹¤ìŠµì„ ë³‘í–‰í•˜ê³ , ì •ê¸°ì ì¸ ë³µìŠµê³¼ ì‹¤ì „ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì§€ì‹ì„ ë‚´ì¬í™”í•´ì•¼ í•©ë‹ˆë‹¤. ë™ë£Œë“¤ê³¼ì˜ í† ë¡ ê³¼ ì§€ì‹ ê³µìœ ë„ í•™ìŠµ íš¨ê³¼ë¥¼ ë†’ì´ëŠ” ì¤‘ìš”í•œ ë°©ë²•ì…ë‹ˆë‹¤.",
            
            "ì—°êµ¬": "ê¸°ìˆ  ì—°êµ¬ëŠ” ë¬¸ì œ ì •ì˜, í˜„í™© ë¶„ì„, í•´ê²° ë°©ì•ˆ ëª¨ìƒ‰, ì‹¤í—˜ ë° ê²€ì¦ì˜ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ  ë™í–¥ì„ íŒŒì•…í•˜ê³ , ê¸°ì¡´ ì†”ë£¨ì…˜ì˜ í•œê³„ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì„ ëœ ì ‘ê·¼ ë°©ë²•ì„ ì°¾ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.",
        }
        
        # ì¿¼ë¦¬ì— ë§ëŠ” í…œí”Œë¦¿ ì°¾ê¸°
        for keyword, template in templates.items():
            if any(keyword in word for word in words) or keyword in query.lower():
                return template
        
        # ê¸°ë³¸ í™•ì¥
        expanded = f"'{query}'ì— ëŒ€í•œ ìƒì„¸í•œ ë‚´ìš©ì…ë‹ˆë‹¤. "
        
        # ê°œë°œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°œë°œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        dev_keywords = ["ì½”ë“œ", "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ì†Œí”„íŠ¸ì›¨ì–´", "ì‹œìŠ¤í…œ", "ê¸°ìˆ "]
        if any(keyword in query for keyword in dev_keywords):
            expanded += "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ì¤‘ìš”í•œ ê°œë…ìœ¼ë¡œ, ì½”ë“œ í’ˆì§ˆê³¼ ê°œë°œ íš¨ìœ¨ì„±ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. "
        
        # í•™ìŠµ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•™ìŠµ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        learning_keywords = ["ë°°ìš°", "í•™ìŠµ", "ê³µë¶€", "ìµíˆ", "ì—°ìŠµ"]
        if any(keyword in query for keyword in learning_keywords):
            expanded += "ì§€ì†ì ì¸ í•™ìŠµê³¼ ì‹¤ìŠµì„ í†µí•´ ìˆ™ë ¨ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        
        expanded += f"ê´€ë ¨ ìë£Œì™€ ì˜ˆì œ, ì‹¤ìŠµ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ {query}ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤."
        
        return expanded


class QueryExpansionEngine:
    """í†µí•© ì¿¼ë¦¬ í™•ì¥ ì—”ì§„"""
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-m3",
        device: Optional[str] = None,
        use_fp16: bool = True,
        enable_hyde: bool = True
    ):
        """
        Args:
            model_name: BGE ëª¨ë¸ëª…
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
            use_fp16: FP16 ì‚¬ìš© ì—¬ë¶€
            enable_hyde: HyDE ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
        """
        self.model_name = model_name
        self.device = device
        self.use_fp16 = use_fp16
        self.enable_hyde = enable_hyde
        
        # ì„œë¸Œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.synonym_expander = KoreanSynonymExpander()
        
        if self.enable_hyde and BGE_AVAILABLE:
            self.hyde_generator = HyDEGenerator(model_name, device, use_fp16)
        else:
            self.hyde_generator = None
            if self.enable_hyde:
                logger.warning("HyDE ê¸°ëŠ¥ì´ ìš”ì²­ë˜ì—ˆì§€ë§Œ BGEê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        logger.info("ì¿¼ë¦¬ í™•ì¥ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def expand_query(
        self,
        query: str,
        include_synonyms: bool = True,
        include_hyde: bool = True,
        max_synonyms: int = 5
    ) -> ExpandedQuery:
        """
        ì¿¼ë¦¬ í™•ì¥ ì‹¤í–‰
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            include_synonyms: ë™ì˜ì–´ í¬í•¨ ì—¬ë¶€
            include_hyde: HyDE í¬í•¨ ì—¬ë¶€
            max_synonyms: ìµœëŒ€ ë™ì˜ì–´ ìˆ˜
            
        Returns:
            í™•ì¥ëœ ì¿¼ë¦¬ ì •ë³´
        """
        logger.info(f"ì¿¼ë¦¬ í™•ì¥ ì‹œì‘: '{query}'")
        
        # ë™ì˜ì–´ í™•ì¥
        synonyms = []
        if include_synonyms:
            synonyms = self.synonym_expander.expand_synonyms(query)
            synonyms = synonyms[:max_synonyms]  # ìµœëŒ€ ìˆ˜ ì œí•œ
            logger.info(f"ë™ì˜ì–´ ë°œê²¬: {len(synonyms)}ê°œ")
        
        # ê´€ë ¨ì–´ (í˜„ì¬ëŠ” ë™ì˜ì–´ì™€ ë™ì¼, í–¥í›„ ì˜ë¯¸ì  ìœ ì‚¬ì–´ë¡œ í™•ì¥ ê°€ëŠ¥)
        related_terms = synonyms.copy()
        
        # í™•ì¥ëœ ìš©ì–´ ëª©ë¡
        expanded_terms = [query] + synonyms + related_terms
        expanded_terms = list(dict.fromkeys(expanded_terms))  # ì¤‘ë³µ ì œê±°
        
        # HyDE ìƒì„±
        hypothetical_doc = None
        if include_hyde and self.hyde_generator:
            hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
            logger.info(f"HyDE ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {len(hypothetical_doc)}ì")
        
        # í™•ì¥ ë°©ë²• ê²°ì •
        expansion_method = []
        if synonyms:
            expansion_method.append("synonyms")
        if hypothetical_doc:
            expansion_method.append("hyde")
        
        expanded_query = ExpandedQuery(
            original_query=query,
            expanded_terms=expanded_terms,
            synonyms=synonyms,
            related_terms=related_terms,
            hypothetical_doc=hypothetical_doc,
            expansion_method="+".join(expansion_method) if expansion_method else "none"
        )
        
        logger.info(f"ì¿¼ë¦¬ í™•ì¥ ì™„ë£Œ: {len(expanded_terms)}ê°œ ìš©ì–´, ë°©ë²•: {expanded_query.expansion_method}")
        
        return expanded_query
    
    def create_expanded_search_queries(self, expanded_query: ExpandedQuery) -> List[str]:
        """í™•ì¥ëœ ì¿¼ë¦¬ë¡œë¶€í„° ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        search_queries = []
        
        # 1. ì›ë³¸ ì¿¼ë¦¬
        search_queries.append(expanded_query.original_query)
        
        # 2. ë™ì˜ì–´ê°€ í¬í•¨ëœ ì¿¼ë¦¬ë“¤
        for synonym in expanded_query.synonyms[:3]:  # ìƒìœ„ 3ê°œë§Œ
            search_queries.append(f"{expanded_query.original_query} {synonym}")
        
        # 3. HyDE ë¬¸ì„œ (ìˆëŠ” ê²½ìš°)
        if expanded_query.hypothetical_doc:
            search_queries.append(expanded_query.hypothetical_doc)
        
        # 4. í™•ì¥ëœ ìš©ì–´ë“¤ì˜ ì¡°í•©
        if len(expanded_query.expanded_terms) > 1:
            # ìƒìœ„ ìš©ì–´ë“¤ì˜ ì¡°í•©
            top_terms = expanded_query.expanded_terms[:4]
            combined_query = " ".join(top_terms)
            search_queries.append(combined_query)
        
        # ì¤‘ë³µ ì œê±°
        search_queries = list(dict.fromkeys(search_queries))
        
        return search_queries


def test_query_expansion():
    """ì¿¼ë¦¬ í™•ì¥ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì¿¼ë¦¬ í™•ì¥ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    
    try:
        # ì¿¼ë¦¬ í™•ì¥ ì—”ì§„ ì´ˆê¸°í™”
        expansion_engine = QueryExpansionEngine(enable_hyde=True)
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "TDD",
            "ë¦¬íŒ©í† ë§ ë°©ë²•",
            "í´ë¦°ì½”ë“œ ì‘ì„±ë²•",
            "ìŠ¤í”„ë§ ë¶€íŠ¸ í•™ìŠµ",
            "ìë°” ê°œë°œ"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
            
            # ì¿¼ë¦¬ í™•ì¥
            expanded = expansion_engine.expand_query(query)
            
            print(f"   ë™ì˜ì–´: {expanded.synonyms}")
            print(f"   í™•ì¥ ìš©ì–´: {expanded.expanded_terms}")
            print(f"   í™•ì¥ ë°©ë²•: {expanded.expansion_method}")
            
            if expanded.hypothetical_doc:
                print(f"   HyDE ë¬¸ì„œ: {expanded.hypothetical_doc[:100]}...")
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_queries = expansion_engine.create_expanded_search_queries(expanded)
            print(f"   ê²€ìƒ‰ ì¿¼ë¦¬ ìˆ˜: {len(search_queries)}")
        
        print("\nâœ… ì¿¼ë¦¬ í™•ì¥ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    test_query_expansion()